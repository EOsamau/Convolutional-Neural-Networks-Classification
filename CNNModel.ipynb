{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries used in the Assignment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data.numpy()        # The data is converted from a PyTorch tensor to a numpy array for easier manipulation\n",
    "        self.targets = targets          #labels\n",
    "        self.transform = transform      #transformations to be applied to the data if necessary\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx].astype(np.uint8) #We want to retrieve the examples by index and convert them to a uint8 type\n",
    "        label = int(self.targets[idx]) #Retrieve the label of the example and convert to integer\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image) #Applying transforms like normalization, resizing, etc.\n",
    "        else:\n",
    "            \n",
    "            image = torch.FloatTensor(image) / 255.0 #Dividing by the maximum value of the grey scale to normalize the data\n",
    "            image = image.unsqueeze(0)  # Adding the 1 channel dimension to the image tensor grey scale\n",
    "            \n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTNet, self).__init__()\n",
    "        \n",
    "        # First Convolutional Block starts with 1 input channel because the images are grey scale\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        )\n",
    "        \n",
    "        # Second Convolutional Block Receives the 32 output channels from the first block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # batch_size [64, 7, 7]\n",
    "        )\n",
    "        \n",
    "        # Third Convolutional Block Receives the 64 output channels from the second block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # batch_size [128, 3, 3]\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten() #We now convert the 3D output from the last convolutional block to a 1D vector i.e 128 x 3 x 3 = 1152\n",
    "        \n",
    "        #Now we work on the 1d vector using fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 3 * 3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10) #The output layer has 10 neurons because we have 10 classes for the Fashion MNIST dataset\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Goal here is to apply the previously defined layers in the forward pass of the network'''\n",
    "        x = self.conv1(x)          \n",
    "        x = self.conv2(x)          \n",
    "        x = self.conv3(x)          \n",
    "        x = self.flatten(x)        \n",
    "        x = self.fc(x)            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))]) #Goal here is to transform the data to a tensor and normalize it for the neural network architecture\n",
    "    \n",
    "    #Loading the FashionMNIST train data from Pytorch datasets in its original form\n",
    "    train_dataset = datasets.FashionMNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=None  )\n",
    "    \n",
    "    #Loading the FashionMNIST test data from Pytorch datasets in its original form\n",
    "    test_dataset = datasets.FashionMNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=None )\n",
    "    \n",
    "    #WE now extract the data and labels from the datasets and apply the transformations to them\n",
    "    custom_train_dataset = FashionMNISTDataset(\n",
    "        train_dataset.data,\n",
    "        train_dataset.targets,\n",
    "        transform=transform) \n",
    "    \n",
    "    custom_test_dataset = FashionMNISTDataset(\n",
    "        test_dataset.data,\n",
    "        test_dataset.targets,\n",
    "        transform=transform)\n",
    "    \n",
    "   \n",
    "    train_loader = DataLoader(\n",
    "        custom_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        custom_test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the data with the Neural Network Architecture Built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=10, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "def save_model(model, path='model.pt'):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Load model weights\n",
    "def load_model(path='model.pt'):\n",
    "    model = FashionMNISTNet()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the NN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 11122795.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 257795.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:00<00:00, 4480288.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 8970617.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Epoch: 0, Batch: 0, Loss: 2.3323\n",
      "Epoch: 0, Batch: 100, Loss: 0.3912\n",
      "Epoch: 0, Batch: 200, Loss: 0.5291\n",
      "Epoch: 0, Batch: 300, Loss: 0.4307\n",
      "Epoch: 0, Batch: 400, Loss: 0.5122\n",
      "Epoch: 0, Batch: 500, Loss: 0.1563\n",
      "Epoch: 0, Batch: 600, Loss: 0.3422\n",
      "Epoch: 0, Batch: 700, Loss: 0.3656\n",
      "Epoch: 0, Batch: 800, Loss: 0.4270\n",
      "Epoch: 0, Batch: 900, Loss: 0.3002\n",
      "Epoch: 1, Batch: 0, Loss: 0.2173\n",
      "Epoch: 1, Batch: 100, Loss: 0.2629\n",
      "Epoch: 1, Batch: 200, Loss: 0.2655\n",
      "Epoch: 1, Batch: 300, Loss: 0.2803\n",
      "Epoch: 1, Batch: 400, Loss: 0.2923\n",
      "Epoch: 1, Batch: 500, Loss: 0.2105\n",
      "Epoch: 1, Batch: 600, Loss: 0.2467\n",
      "Epoch: 1, Batch: 700, Loss: 0.1749\n",
      "Epoch: 1, Batch: 800, Loss: 0.3282\n",
      "Epoch: 1, Batch: 900, Loss: 0.3768\n",
      "Epoch: 2, Batch: 0, Loss: 0.1442\n",
      "Epoch: 2, Batch: 100, Loss: 0.2409\n",
      "Epoch: 2, Batch: 200, Loss: 0.1589\n",
      "Epoch: 2, Batch: 300, Loss: 0.3776\n",
      "Epoch: 2, Batch: 400, Loss: 0.2509\n",
      "Epoch: 2, Batch: 500, Loss: 0.3021\n",
      "Epoch: 2, Batch: 600, Loss: 0.1856\n",
      "Epoch: 2, Batch: 700, Loss: 0.1291\n",
      "Epoch: 2, Batch: 800, Loss: 0.2452\n",
      "Epoch: 2, Batch: 900, Loss: 0.3502\n",
      "Epoch: 3, Batch: 0, Loss: 0.2425\n",
      "Epoch: 3, Batch: 100, Loss: 0.2336\n",
      "Epoch: 3, Batch: 200, Loss: 0.1613\n",
      "Epoch: 3, Batch: 300, Loss: 0.1820\n",
      "Epoch: 3, Batch: 400, Loss: 0.1499\n",
      "Epoch: 3, Batch: 500, Loss: 0.2379\n",
      "Epoch: 3, Batch: 600, Loss: 0.2490\n",
      "Epoch: 3, Batch: 700, Loss: 0.2808\n",
      "Epoch: 3, Batch: 800, Loss: 0.2004\n",
      "Epoch: 3, Batch: 900, Loss: 0.1683\n",
      "Epoch: 4, Batch: 0, Loss: 0.1472\n",
      "Epoch: 4, Batch: 100, Loss: 0.1298\n",
      "Epoch: 4, Batch: 200, Loss: 0.1752\n",
      "Epoch: 4, Batch: 300, Loss: 0.2738\n",
      "Epoch: 4, Batch: 400, Loss: 0.0500\n",
      "Epoch: 4, Batch: 500, Loss: 0.0744\n",
      "Epoch: 4, Batch: 600, Loss: 0.2063\n",
      "Epoch: 4, Batch: 700, Loss: 0.1055\n",
      "Epoch: 4, Batch: 800, Loss: 0.2444\n",
      "Epoch: 4, Batch: 900, Loss: 0.2678\n",
      "Epoch: 5, Batch: 0, Loss: 0.1190\n",
      "Epoch: 5, Batch: 100, Loss: 0.1202\n",
      "Epoch: 5, Batch: 200, Loss: 0.1094\n",
      "Epoch: 5, Batch: 300, Loss: 0.1129\n",
      "Epoch: 5, Batch: 400, Loss: 0.1258\n",
      "Epoch: 5, Batch: 500, Loss: 0.1709\n",
      "Epoch: 5, Batch: 600, Loss: 0.0620\n",
      "Epoch: 5, Batch: 700, Loss: 0.2323\n",
      "Epoch: 5, Batch: 800, Loss: 0.1664\n",
      "Epoch: 5, Batch: 900, Loss: 0.1498\n",
      "Epoch: 6, Batch: 0, Loss: 0.1169\n",
      "Epoch: 6, Batch: 100, Loss: 0.0459\n",
      "Epoch: 6, Batch: 200, Loss: 0.4457\n",
      "Epoch: 6, Batch: 300, Loss: 0.1131\n",
      "Epoch: 6, Batch: 400, Loss: 0.0746\n",
      "Epoch: 6, Batch: 500, Loss: 0.2259\n",
      "Epoch: 6, Batch: 600, Loss: 0.1171\n",
      "Epoch: 6, Batch: 700, Loss: 0.2357\n",
      "Epoch: 6, Batch: 800, Loss: 0.0551\n",
      "Epoch: 6, Batch: 900, Loss: 0.0667\n",
      "Epoch: 7, Batch: 0, Loss: 0.0705\n",
      "Epoch: 7, Batch: 100, Loss: 0.0549\n",
      "Epoch: 7, Batch: 200, Loss: 0.0634\n",
      "Epoch: 7, Batch: 300, Loss: 0.1026\n",
      "Epoch: 7, Batch: 400, Loss: 0.0784\n",
      "Epoch: 7, Batch: 500, Loss: 0.1144\n",
      "Epoch: 7, Batch: 600, Loss: 0.1651\n",
      "Epoch: 7, Batch: 700, Loss: 0.1874\n",
      "Epoch: 7, Batch: 800, Loss: 0.2182\n",
      "Epoch: 7, Batch: 900, Loss: 0.1581\n",
      "Epoch: 8, Batch: 0, Loss: 0.0956\n",
      "Epoch: 8, Batch: 100, Loss: 0.0450\n",
      "Epoch: 8, Batch: 200, Loss: 0.1630\n",
      "Epoch: 8, Batch: 300, Loss: 0.0397\n",
      "Epoch: 8, Batch: 400, Loss: 0.1554\n",
      "Epoch: 8, Batch: 500, Loss: 0.2121\n",
      "Epoch: 8, Batch: 600, Loss: 0.1348\n",
      "Epoch: 8, Batch: 700, Loss: 0.0825\n",
      "Epoch: 8, Batch: 800, Loss: 0.0517\n",
      "Epoch: 8, Batch: 900, Loss: 0.1095\n",
      "Epoch: 9, Batch: 0, Loss: 0.1174\n",
      "Epoch: 9, Batch: 100, Loss: 0.0827\n",
      "Epoch: 9, Batch: 200, Loss: 0.1146\n",
      "Epoch: 9, Batch: 300, Loss: 0.1191\n",
      "Epoch: 9, Batch: 400, Loss: 0.0482\n",
      "Epoch: 9, Batch: 500, Loss: 0.0422\n",
      "Epoch: 9, Batch: 600, Loss: 0.1766\n",
      "Epoch: 9, Batch: 700, Loss: 0.1079\n",
      "Epoch: 9, Batch: 800, Loss: 0.0849\n",
      "Epoch: 9, Batch: 900, Loss: 0.1712\n",
      "Accuracy: 92.42%\n",
      "Test Accuracy: 92.42%\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = create_data_loaders(batch_size=64)\n",
    "\n",
    "model = FashionMNISTNet()\n",
    "\n",
    "model = train_model(model, train_loader, epochs=10, learning_rate=0.001)\n",
    "\n",
    "accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving weights and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model.pt\"\n",
    "EPOCH = 10\n",
    "\n",
    "# The save function creates a binary storing all our data for us\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model.pt\"\n",
    "\n",
    "# Create a new \"blank\" model to load our information into\n",
    "model = FashionMNISTNet()\n",
    "\n",
    "# Recreate our optimizer\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Load back all of our data from the file\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "EPOCH = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to model_weights.pt\n"
     ]
    }
   ],
   "source": [
    "def save_model_weights(model, path='model_weights.pt'):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model weights saved to {path}\")\n",
    "\n",
    "save_model_weights(model, 'model_weights.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
